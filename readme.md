# 📄 CogniDoc: AI-Powered Document Query System

**Live Demo:** [cognidoc.netlify.app](https://cognidoc.netlify.app)

CogniDoc is a full-stack, AI-powered web application that transforms static PDF documents into interactive conversational partners. Users can upload a PDF and ask questions in natural language to receive intelligent, context-aware answers generated by a sophisticated AI pipeline.

---

## ✨ Demo

The application provides a clean, two-step user experience:

1. **Before Upload:** A clean interface prompts the user to upload a file.  
![Demo Screenshot](https://github.com/deveshio/Pdf-reader-Query/blob/main/media/image1.png)

2. **After Upload & Query:** After processing, the app confirms the document is ready and provides an interface for asking questions and receiving AI-generated answers.
![Demo Screenshot](https://github.com/deveshio/Pdf-reader-Query/blob/main/media/image1.png)
---

## 🚀 Key Features

- **Dynamic PDF Upload:** Users can upload any PDF document for analysis.  
- **AI-Powered Q&A:** Leverages a Retrieval-Augmented Generation (RAG) pipeline to provide accurate, context-aware answers.  
- **Decoupled Full-Stack Architecture:** Built with a separate React frontend and a FastAPI backend for scalability and maintainability.  
- **Persistent Vector Storage:** Utilizes Astra DB to store document embeddings for efficient, low-latency semantic searches.  
- **Real-time Semantic Search:** Finds the most relevant parts of the document to answer a user's question, no matter how it’s phrased.

---

## 🛠️ Tech Stack

| **Category** | **Technology** |
|---------------|----------------|
| **Frontend** | React.js |
| **Backend** | FastAPI, Python |
| **AI / NLP** | LangChain, Google Gemini API (Answer Generation), Hugging Face (Embeddings) |
| **Database** | Astra DB (Vector Store) |
| **Deployment** | Netlify (Frontend), Render (Backend), Git |

---

## 📂 Project Structure

```
cognidoc/
│
├── 📂 backend/
│ ├── 📄 main.py             # FastAPI application logic
│ ├── 📄 requirements.txt    # Python dependencies for the backend
│ ├── 📄 .env                # Secret keys for local development
│ └── 📄 .gitignore          # Ignores .venv, .env, and pycache
│
├── 📂 frontend/
│ ├── 📂 public/
│ │ └── 📄 index.html        # Main HTML page for the React app
│ │
│ ├── 📂 src/
│ │ ├── 📂 components/
│ │ │ ├── 📄 FileUploader.js # File upload UI component
│ │ │ └── 📄 QueryForm.js    # Question form component
│ │ │
│ │ ├── 📂 services/
│ │ │ └── 📄 api.js          # Handles all API calls to the backend
│ │ │
│ │ ├── 📄 App.js            # Main component orchestrating the UI
│ │ ├── 📄 App.css           # Styles for the App component
│ │ ├── 📄 index.js          # Entry point for the React app
│ │ └── 📄 index.css         # Global styles
│ │
│ ├── 📄 package.json        # Frontend dependencies
│ ├── 📄 package-lock.json   # Locks dependency versions
│ └── 📄 .gitignore          # Ignores node_modules, build files.
│
└── 📄 README.md             # Project documentation

```
---

## ⚙️ How It Works: The RAG Pipeline

CogniDoc is built around a **Retrieval-Augmented Generation (RAG)** pipeline, ensuring that the AI’s answers are grounded in the uploaded document.

### **1. Upload & Processing (`/upload` endpoint):**

- The user uploads a PDF via the React frontend.  
- The file is sent to the FastAPI backend.  
- The backend extracts all text from the PDF.  
- The text is split into smaller, manageable chunks using LangChain.  
- Each chunk is converted into a numerical representation (vector embedding) using a Hugging Face sentence-transformer model.  
- These embeddings are stored in the Astra DB vector store.

### **2. Query & Answer Generation (`/query` endpoint):**

- The user asks a question in the React frontend.  
- The question is sent to the FastAPI backend.  
- The backend performs a semantic search in Astra DB to find the most relevant text chunks.  
- These chunks, along with the original question, are passed as context to the **Google Gemini API**.  
- The Gemini model generates a comprehensive, human-like answer based on the provided context.  
- The final answer is sent back to the React frontend and displayed to the user.

---

## 🏁 Getting Started: Running the Project Locally

To run this project locally, set up both the backend and frontend.

### **Prerequisites**
- Node.js (v18 or newer)  
- Python 3.11 or newer  
- Git for cloning the repository  
- API keys for Google Gemini and Astra DB

---

### **1. Clone the Repository**

```bash
git clone https://github.com/deveshio/Pdf-reader-Query.git
cd cognidoc
```
### ***2. Backend Setup***
```
# navigate to backend 
cd backend

# Use py -3.11 or python3.11 depending on your system
py -3.11 -m venv .venv
.\.venv\Scripts\activate

# Install the requirements
pip install -r requirements.txt

```

Configure your secrets by creating a .env
```
GOOGLE_AI_KEY="your_google_api_key_here"
ASTRA_DB_APPLICATION_TOKEN="your_astra_token_here"
ASTRA_DB_ID="your_astra_db_id_here"
```

Run the backend server.
```
uvicorn main:app --reload
```

### ***2. Backend Setup***
```
# navigate to Frontend
cd frontned

# Install dependencies:
npm install

# run the dev environment
npm start

```


## 🙏 Thank You

Thank you for taking the time to read through this project and for using **CogniDoc** wisely.

If you have any **feature updates or improvements** in mind, I’d be happy to review your **pull requests** and collaborate to make the project even better!
